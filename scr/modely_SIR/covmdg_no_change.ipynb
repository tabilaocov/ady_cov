{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covmdg_no_change.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTShgRv23Rpd//OlmK9okA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/herysedra/ady_cov/blob/master/scr/modely_SIR/covmdg_no_change.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1JSB-y8XNEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "import matplotlib\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "confirmed_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
        "confirmed_cases = pd.read_csv(confirmed_cases_url, sep=',')\n",
        "deaths_url =  'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
        "deaths = pd.read_csv(deaths_url, sep=',')\n",
        "path_to_save = '/content/sample_data/covmdg1/'\n",
        "path_data = '/content/sample_data/covmdg1/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn8dI1PiXQgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delay_cases(new_I_t, len_new_I_t, len_new_cases_obs , delay, delay_arr):\n",
        "\n",
        "\n",
        "    delay_mat = make_delay_matrix(n_rows=len_new_I_t, \n",
        "                                  n_columns=len_new_cases_obs, initial_delay=delay_arr)\n",
        "    inferred_cases = interpolate(new_I_t, delay, delay_mat)\n",
        "    return inferred_cases \n",
        "\n",
        "def make_delay_matrix(n_rows, n_columns, initial_delay=0):\n",
        "    \"\"\"\n",
        "    Has in each entry the delay between the input with size n_rows and the output\n",
        "    with size n_columns\n",
        "    \"\"\"\n",
        "    size = max(n_rows, n_columns)\n",
        "    mat = np.zeros((size, size))\n",
        "    for i in range(size):\n",
        "        diagonal = np.ones(size-i)*(initial_delay + i)\n",
        "        mat += np.diag(diagonal, i)\n",
        "    for i in range(1, size):\n",
        "        diagonal = np.ones(size-i)*(initial_delay - i)\n",
        "        mat += np.diag(diagonal, -i)\n",
        "    return mat[:n_rows, :n_columns]\n",
        "    \n",
        "\n",
        "def interpolate(array, delay, delay_matrix):\n",
        "    interp_matrix = tt.maximum(1-tt.abs_(delay_matrix - delay), 0)\n",
        "    interpolation = tt.dot(array,interp_matrix)\n",
        "    return interpolation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhKRRTltXSuu",
        "colab_type": "code",
        "outputId": "6855e97c-204b-4cdf-e138-0d7ea5d52358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import pymc3 as pm\n",
        "import theano.tensor as tt\n",
        "import theano\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra comments:\n",
        "libraries and modules : pymc3 (on Bayesian statistical modeling),  \n",
        "theano (for manipulating and evaluating mathematical expressions, especially \n",
        "matrix-valued ones)\n",
        "\"\"\"\n",
        "\n",
        "date_data_begin = datetime.date(2020,4,1)\n",
        "date_data_end = datetime.date(2020,4,15)\n",
        "num_days_to_predict = 28\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra:\n",
        "Above are the period of interest from which the data will be retrieved.\n",
        "\"\"\"\n",
        "\n",
        "diff_data_sim = 16 # should be significantly larger than the expected delay, in \n",
        "                   # order to always fit the same number of data points.\n",
        "\n",
        "\"\"\"\n",
        "Because of the reporting delay, in order to analyze the reported new cases \n",
        "between date_data_begin and date_data_end, we have to look at simulated/inferred\n",
        "values of new cases at time starting before t - delay.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "date_begin_sim = date_data_begin - datetime.timedelta(days = diff_data_sim)\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra: (corrected)\n",
        "diff_data_sim: number of days which separate the date_data_begin (21 march 2020) \n",
        "and the date_begin_sim (14 february 2020: the simulation starts )\n",
        "\"\"\"\n",
        "format_date = lambda date_py: '{}/{}/{}'.format(date_py.month, date_py.day,\n",
        "                                                 str(date_py.year)[2:4])\n",
        "date_formatted_begin = format_date(date_data_begin)\n",
        "date_formatted_end = format_date(date_data_end)\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra & Joely: format date\n",
        "\"\"\"\n",
        "\n",
        "cases_obs =  np.array(\n",
        "    confirmed_cases.loc[confirmed_cases[\"Country/Region\"] == \"Madagascar\", \n",
        "                        date_formatted_begin:date_formatted_end])[0]\n",
        "#cases_obs = np.concatenate([np.nan*np.ones(diff_data_sim), cases_obs])\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra: (corrected)\n",
        "cases_obs : the number of infected cases in tana from the \n",
        "date_data_begin (1 march 2020) to the date_begin_sim (14 february 2020).\n",
        "\"\"\"\n",
        "\n",
        "print('Cases of ({}): {} and '\n",
        "      'day before that: {}'.format(date_data_end.isoformat(), *cases_obs[:-3:-1]))\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra & Joely: output about the new cases at the begin day of \n",
        "the forecasting and at the day before.\n",
        "\"\"\"\n",
        "\n",
        "num_days = (date_data_end - date_begin_sim).days\n",
        "# \n",
        "date_today = date_data_end + datetime.timedelta(days=1)\n",
        "\n",
        "print(cases_obs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cases of (2020-04-15): 110 and day before that: 108\n",
            "[ 57  59  70  70  72  82  88  93  93  93 102 106 106 108 110]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTVLd3XVXXg5",
        "colab_type": "code",
        "outputId": "e2ac6cf7-1671-4ed7-a2ca-b5eaea0364b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "\n",
        "# ------------------------------------------------------------------------------ #\n",
        "# model setup and training\n",
        "# ------------------------------------------------------------------------------ #\n",
        "np.random.seed(0)\n",
        "\n",
        "def SIR_model(λ, μ, S_begin, I_begin, N):\n",
        "    new_I_0 = tt.zeros_like(I_begin)\n",
        "    def next_day(λ, S_t, I_t, _):\n",
        "        new_I_t = λ/N*I_t*S_t\n",
        "        S_t = S_t - new_I_t\n",
        "        I_t = I_t + new_I_t - μ * I_t\n",
        "        return S_t, I_t, new_I_t\n",
        "    outputs , _  = theano.scan(fn=next_day, sequences=[λ], \n",
        "                               outputs_info=[S_begin, I_begin, new_I_0])\n",
        "    S_all, I_all, new_I_all = outputs\n",
        "    return S_all, I_all, new_I_all\n",
        "\n",
        "    \"\"\"\n",
        "    Mahasedra:\n",
        "    SIR_model(): provides all values of S, I and new infected cases given\n",
        "    by the SIR model with the initial conditions S_begin, I_begin, N.\n",
        "    To be checked\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "with pm.Model() as model:\n",
        "    # true cases at begin of loaded data but we do not know the real number\n",
        "    I_begin = pm.HalfCauchy('I_begin', beta=100)\n",
        "\n",
        "    # fraction of people that are newly infected each day\n",
        "    λ = pm.Lognormal(\"λ\", mu=np.log(0.4), sigma=0.5)\n",
        "\n",
        "    # fraction of people that recover each day, recovery rate mu\n",
        "    μ = pm.Lognormal('μ', mu=np.log(1/8), sigma=0.2)\n",
        "\n",
        "    # delay in days between contracting the disease and being recorded\n",
        "    delay = pm.Lognormal(\"delay\", mu=np.log(8), sigma=0.2)\n",
        "\n",
        "    # prior of the error of observed cases\n",
        "    σ_obs = pm.HalfCauchy(\"σ_obs\", beta=10)\n",
        "\n",
        "    N_tana = 2e6\n",
        "\n",
        "    \"\"\"\n",
        "    Mahasedra: I suppose that only part of the population can be really susceptible\n",
        "    to be infected.\n",
        "    \"\"\"\n",
        "\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    # training the model with loaded data\n",
        "    # -------------------------------------------------------------------------- #\n",
        "\n",
        "    S_begin = N_tana - I_begin\n",
        "    S_past, I_past, new_I_past = SIR_model(λ=λ * tt.ones(num_days-1), μ=μ, \n",
        "                                               S_begin=S_begin, I_begin=I_begin,\n",
        "                                               N=N_tana)\n",
        "    new_cases_obs = np.diff(cases_obs)\n",
        "    new_cases_inferred = delay_cases(new_I_past, len_new_I_t=num_days - 1, \n",
        "                                     len_new_cases_obs=len(new_cases_obs), \n",
        "                                     delay=delay, delay_arr=diff_data_sim)\n",
        "\n",
        "    # Approximates Poisson\n",
        "    # calculate the likelihood of the model:\n",
        "    # observed cases are distributed following studentT around the model\n",
        "    pm.StudentT(\n",
        "        \"obs\",\n",
        "        nu=4,\n",
        "        mu=new_cases_inferred,\n",
        "        sigma=(new_cases_inferred)**0.5 * σ_obs,\n",
        "        observed=new_cases_obs)  \n",
        "    \n",
        "    S_past = pm.Deterministic('S_past', S_past)\n",
        "    I_past = pm.Deterministic('I_past', I_past)\n",
        "    new_I_past = pm.Deterministic('new_I_past', new_I_past)\n",
        "    new_cases_past = pm.Deterministic('new_cases_past', new_cases_inferred)\n",
        "\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    # prediction, start with no changes in policy\n",
        "    # -------------------------------------------------------------------------- #\n",
        "\n",
        "    S_begin = S_past[-1]\n",
        "    I_begin = I_past[-1]\n",
        "    forecast_no_change = SIR_model(λ=λ*tt.ones(num_days_to_predict), μ=μ, \n",
        "                        S_begin=S_begin, I_begin=I_begin, N=N_tana)\n",
        "    S_no_change, I_no_change, new_I_no_change = forecast_no_change\n",
        "\n",
        "    #saves the variables for later retrieval\n",
        "    pm.Deterministic('S_no_change', S_no_change)\n",
        "    pm.Deterministic('I_no_change', I_no_change)\n",
        "    pm.Deterministic('new_I_no_change', new_I_no_change)\n",
        "\n",
        "    \"\"\"\n",
        "    PyMC3 allows you to freely do algebra with RVs in all kinds of ways (...).\n",
        "    While these transformations work seamlessly, their results are not \n",
        "    stored automatically. Thus, if you want to keep track of a transformed \n",
        "    variable, you have to use pm.Deterministic.\n",
        "    \"\"\"\n",
        "\n",
        "    new_cases_inferred = delay_cases(tt.concatenate([new_I_past[-diff_data_sim:], new_I_no_change]), \n",
        "                                     len_new_I_t=diff_data_sim + num_days_to_predict, \n",
        "                                     len_new_cases_obs=num_days_to_predict, \n",
        "                                     delay=delay, delay_arr=diff_data_sim)\n",
        "    pm.Deterministic('new_cases_no_change', new_cases_inferred)\n",
        "\n",
        "    time_beg = time.time()\n",
        "    trace = pm.sample(draws=3000, tune=800, chains=2)\n",
        "    print(\"Model run in {:.2f} s\".format(time.time() - time_beg))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auto-assigning NUTS sampler...\n",
            "Initializing NUTS using jitter+adapt_diag...\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "Sequential sampling (2 chains in 1 job)\n",
            "NUTS: [σ_obs, delay, μ, λ, I_begin]\n",
            "100%|██████████| 3800/3800 [01:08<00:00, 55.69it/s]\n",
            "100%|██████████| 3800/3800 [01:07<00:00, 56.10it/s]\n",
            "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
            "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
            "The number of effective samples is smaller than 25% for some parameters.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model run in 206.95 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQd69D2XuAM0",
        "colab_type": "code",
        "outputId": "96fe885f-6cfa-4565-f557-4a18273cef1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "C_nc = np.array(new_I_no_change)\n",
        "C_nc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(Subtensor{int64::}.0, dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5h-esCsXYW5",
        "colab_type": "code",
        "outputId": "a256e8be-44af-4f27-d2bc-a8bbcd9abdba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "legends_lang = {\n",
        "    \"english\": [\n",
        "        # bottom left\n",
        "        \"Confirmed cases\",\n",
        "        [\n",
        "            \"No social distancing\",\n",
        "            \"Mild social distancing\",\n",
        "            \"Strong social distancing\",\n",
        "            \"Strong social distancing since 5 days ago\",\n",
        "        ],\n",
        "        \"Days since intervention\",\n",
        "        \"Total confirmed cases in Tana\",\n",
        "        \"Start of intervention\",\n",
        "        # bottom right\n",
        "        'Confirmed cases',['Strong social distancing:',\n",
        "                           '  starting at day 0', \n",
        "                           '  starting at day 5',\n",
        "                           \"  starting at day -5\"],\n",
        "        'Days since intervention',\n",
        "        'Total confirmed cases in Madagascar',\n",
        "        'Start of intervention',\n",
        "        \"Spreading\\nrate\",\n",
        "        ['Strong social distancing',\n",
        "         'Strong social distancing\\n  with long transient', \n",
        "         '  with immediate change'],\n",
        "    ],\n",
        "}\n",
        "\n",
        "obs_cases_labels = ['new_cases_no_change', 'new_cases_soc_dist', \n",
        "                    'new_cases_isol', 'new_cases_isol_later','new_cases_earlier', \n",
        "                    'new_cases_long_trans','new_cases_immedi']\n",
        "\n",
        "# label the variables related to the new_cases_inferred\n",
        "\n",
        "cases_obs_to_plot = np.array(confirmed_cases.loc[confirmed_cases['Country/Region'] == 'Madagascar', \n",
        "                                                 date_formatted_begin:date_formatted_end])[0]\n",
        "cases_obs_to_plot_future = np.array(confirmed_cases.loc[confirmed_cases['Country/Region'] == 'Madagascar', date_formatted_end:])[0]\n",
        "\n",
        "print(cases_obs_to_plot)\n",
        "print(cases_obs_to_plot_future)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 57  59  70  70  72  82  88  93  93  93 102 106 106 108 110]\n",
            "[110 111 117]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLBueFggZ26n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}